
# Reunião 1 - 22/03/2024

## Utilizar modelos já treinados
Classificar reviews como positivo, negativo ou neutro e corrigir, via anotação, as predições inconsistentes.
Utilizar Modelos do Hugging Face:
   - https://huggingface.co/models?pipeline_tag=text-classification&language=pt&sort=trending
   - https://huggingface.co/citizenlab/twitter-xlm-roberta-base-sentiment-finetunned
   - https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment

### Tarefas
   - [X] Fazer a predição em reviews positivos e corrigir
   - [X] Fazer a predição em reviews negativos e corrigir
   - [X] Fazer a distribuição de cada entidade para verificar se o modelo está desbalanceado
   - Análise do tamanho do dataset. Quantidade de tokens:
     - [X] boxplot
     - [X] histograma
   - [X] Corrigir Wordcloud exibindo aspas
   - [ ] Tokenização
   - [ ] Fazer o finetuning com o BERTImbau
   - [ ] Usar o modelo para classificar os sentimentos

## Ferramentas de anotação para corrigir predições
   - [prodigy](https://prodi.gy/)
   - [doccano](https://github.com/doccano/doccano)

### **Tarefas**
- [X] ~~Usar algum das ferremantas indicadas~~
- [X] Criar a própria ferramenta de Anotação usando Streamlit
- [X] Corrigir predições positivas
- [X] Corrigir predições negativas

## Artigo Científico

### Tarefas
   - [ ] Escrever no trabalho a metodologia de anotação:
  Ex.: usei o modelo xyz para chegar a um consenso e decidir qual sentimento se trata, se é realmente negativo, positivo ou neutro.
   - [ ] Análise do tamanho do dataset. Quantidade de tokens:
     - [ ] boxplot
     - [ ] histograma
   - [ ] Anotação de Dados

## Anotações
- Em alguns modelos pode-se deixar de transformar as letras para minúsculo

- Como o BERT será utilizado, usar o tokenizer e verificar a quantidade de tokes de cada texto para verificar se algum irá estourar o limite de 512 tokens
